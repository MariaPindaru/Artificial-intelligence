{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:51:53.388779Z",
     "start_time": "2021-05-07T12:51:52.587585Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:51:54.545788Z",
     "start_time": "2021-05-07T12:51:54.538040Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "epochs = 200\n",
    "learning_rate = 0.5\n",
    "hidden_layer_size = 32\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:51:57.027197Z",
     "start_time": "2021-05-07T12:51:57.015971Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    pickle_file = 'mnist.pkl'\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    return train_set[0], train_set[1], test_set[0], test_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:51:58.251437Z",
     "start_time": "2021-05-07T12:51:58.235427Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(value):\n",
    "    return np.maximum(0, value)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    x[x <= 0] = 0\n",
    "    x[x > 0] = 1\n",
    "    return x\n",
    "\n",
    "def softmax(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "def softmax_deriv(z, i, j):\n",
    "    return softmax(z,i) * (1 - softmax(z, i)) if i == j else - softmax(z, i) * softmax(z, j)\n",
    "\n",
    "def one_hot(val, classes):\n",
    "    one_hot = np.zeros(classes)\n",
    "    one_hot[val] = 1\n",
    "    return one_hot\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    logprobs = y_true * np.log(y_pred)\n",
    "    cost = - (1.0 / y_true.shape[0]) * np.sum(logprobs)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:01.336625Z",
     "start_time": "2021-05-07T12:52:01.320045Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_samples(x_set, y_set):\n",
    "    x_set_initial = np.dot(x_set, 255)\n",
    "    size = x_set.shape[0]\n",
    "\n",
    "    fig, ax = plt.subplots(size // 4, 4, figsize=(20, 10))\n",
    "    for k in range(size):\n",
    "        row, col = k // 4, k % 4\n",
    "\n",
    "        # Make those columns into a array of 8-bits pixels\n",
    "        # The pixel intensity values are integers from 0 to 255\n",
    "        pixels = np.array(x_set_initial[k], dtype='uint8')\n",
    "\n",
    "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "        n = int(np.sqrt(len(pixels)))\n",
    "        assert n ** 2 == len(pixels)\n",
    "        pixels = pixels.reshape(n, n)\n",
    "        ax[row, col].imshow(pixels, cmap='gray')\n",
    "        ax[row, col].set_title('Eticheta {label}'.format(label=y_set[k]))\n",
    "        ax[row, col].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:05.600031Z",
     "start_time": "2021-05-07T12:52:02.818556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_x, train_set_y, test_set_x, test_set_y  = load_dataset()\n",
    "y = np.array([one_hot(train_set_y[i], num_classes) for i in range(train_set_y.size)])\n",
    "show_samples(train_set_x[:16], train_set_y[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagation\n",
    "\n",
    "$z_1 = x W_1^T + b_1$\n",
    "\n",
    "$a_1 = relu(z_1)$\n",
    "\n",
    "$z_2 = a_1 W_2^T + b_2$\n",
    "\n",
    "$a_2 = softmax(z_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:07.804064Z",
     "start_time": "2021-05-07T12:52:07.795816Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_prop(set_x, W1, b1, W2, b2):\n",
    "    \n",
    "    z1 = np.matmul(set_x, W1.T) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.matmul(a1, W2.T) + b2\n",
    "    a2 = softmax(z2)\n",
    "    \n",
    "    cache = (set_x, a1, a2)\n",
    "    return a2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:33:28.210619Z",
     "start_time": "2021-05-07T12:33:28.189840Z"
    }
   },
   "source": [
    "# Back propagation\n",
    "\n",
    "$\\frac{\\partial H}{\\partial z^{(2)}} = \\delta^{(2)} = \\frac{1}{n} (a^{(2)} - \\hat y) $\n",
    "\n",
    "$\\frac{\\partial H}{\\partial W^{(2)}} =  (\\delta^{(2)})^T a_1$\n",
    "\n",
    "$\\frac{\\partial H}{\\partial b^{(2)}} = \\sum^n_{i = 1} \\delta^{(2)}_i$\n",
    "\n",
    "$\\frac{\\partial H}{\\partial z^{(1)}} = \\delta^{(1)} = \\delta^{(2)}  W^{(2)}  relu(z^{(1)})' $\n",
    "\n",
    "$\\frac{\\partial H}{\\partial W^{(1)}} = (\\delta^{(1)})^T x$\n",
    "\n",
    "$\\frac{\\partial H}{\\partial b^{(1)}} = \\sum^n_{i = 1} \\delta^{(1)}_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:09.814721Z",
     "start_time": "2021-05-07T12:52:09.800147Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_grads(cache, y):\n",
    "    x, a1, a2 = cache\n",
    "    \n",
    "    delta2 = (1.0 / train_set_x.shape[0]) * (a2 - y)\n",
    "    dw2 = np.matmul(delta2.T, a1)\n",
    "    db2 = np.sum(delta2, axis=0, keepdims=True)\n",
    "    \n",
    "    delta1 = np.matmul(delta2, W2) * relu_deriv(a1)\n",
    "\n",
    "    dw1 = np.matmul(delta1.T, x)\n",
    "    db1 = np.sum(delta1, axis=0, keepdims=True)\n",
    "    \n",
    "    return dw2, db2, dw1, db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:11.889914Z",
     "start_time": "2021-05-07T12:52:11.882409Z"
    }
   },
   "outputs": [],
   "source": [
    "def back_prop(cache, y, W2, b2, W1, b1):\n",
    "    grads = compute_grads(cache, y)\n",
    "\n",
    "    W2 = W2 - learning_rate * grads[0]\n",
    "    b2 = b2 - learning_rate * grads[1]\n",
    "    W1 = W1 - learning_rate * grads[2]\n",
    "    b1 = b1 - learning_rate * grads[3]\n",
    "    \n",
    "    return W2, b2, W1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:13.660728Z",
     "start_time": "2021-05-07T12:52:13.646005Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    accuracy = ((y_pred == y_true).sum() * 100) / y_true.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T13:01:13.109682Z",
     "start_time": "2021-05-07T13:01:13.098510Z"
    }
   },
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:16.118993Z",
     "start_time": "2021-05-07T12:52:16.112095Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = np.random.normal(0, 0.001, (hidden_layer_size, train_set_x.shape[1]))\n",
    "b1 = np.zeros(hidden_layer_size)\n",
    "W2 = np.random.normal(0, 0.001, (num_classes, hidden_layer_size))\n",
    "b2 = np.zeros(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:29:04.185695Z",
     "start_time": "2021-05-07T12:25:01.137012Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 2.3025902277787993\n",
      "Loss at epoch 2: 2.3024251322996294\n",
      "Loss at epoch 3: 2.302275072915765\n",
      "Loss at epoch 4: 2.3021363409720594\n",
      "Loss at epoch 5: 2.3020053519108883\n",
      "Loss at epoch 6: 2.3018780037936417\n",
      "Loss at epoch 7: 2.3017489839741088\n",
      "Loss at epoch 8: 2.3016109904183235\n",
      "Loss at epoch 9: 2.3014532954361355\n",
      "Loss at epoch 10: 2.3012598600648078\n",
      "Loss at epoch 11: 2.3010064488522928\n",
      "Loss at epoch 12: 2.3006553324246064\n",
      "Loss at epoch 13: 2.300147600559356\n",
      "Loss at epoch 14: 2.299391335015809\n",
      "Loss at epoch 15: 2.2982430718131783\n",
      "Loss at epoch 16: 2.296479825335382\n",
      "Loss at epoch 17: 2.2937589551447726\n",
      "Loss at epoch 18: 2.289565397787065\n",
      "Loss at epoch 19: 2.283153040972933\n",
      "Loss at epoch 20: 2.2735094676399394\n",
      "Loss at epoch 21: 2.259410584511397\n",
      "Loss at epoch 22: 2.239672215984713\n",
      "Loss at epoch 23: 2.213652090369051\n",
      "Loss at epoch 24: 2.1816817373223327\n",
      "Loss at epoch 25: 2.1447459416475243\n",
      "Loss at epoch 26: 2.103085440528422\n",
      "Loss at epoch 27: 2.0551986514979594\n",
      "Loss at epoch 28: 1.9983258873365344\n",
      "Loss at epoch 29: 1.9297173249087176\n",
      "Loss at epoch 30: 1.8480280519542882\n",
      "Loss at epoch 31: 1.754215911908301\n",
      "Loss at epoch 32: 1.651702070339259\n",
      "Loss at epoch 33: 1.5458655344580223\n",
      "Loss at epoch 34: 1.4430716922794025\n",
      "Loss at epoch 35: 1.3487238369308228\n",
      "Loss at epoch 36: 1.265368886481066\n",
      "Loss at epoch 37: 1.192961031042713\n",
      "Loss at epoch 38: 1.1302602653761975\n",
      "Loss at epoch 39: 1.0756870170949522\n",
      "Loss at epoch 40: 1.0277477772649146\n",
      "Loss at epoch 41: 0.9851896607568292\n",
      "Loss at epoch 42: 0.9470361719850373\n",
      "Loss at epoch 43: 0.9125346348253154\n",
      "Loss at epoch 44: 0.8811584473793915\n",
      "Loss at epoch 45: 0.8527119600331958\n",
      "Loss at epoch 46: 0.8282971641881787\n",
      "Loss at epoch 47: 0.8153964177306088\n",
      "Loss at epoch 48: 0.8589481556663955\n",
      "Loss at epoch 49: 1.1273927997195132\n",
      "Loss at epoch 50: 1.9530049175086401\n",
      "Loss at epoch 51: 1.9862739868607475\n",
      "Loss at epoch 52: 1.314476377748948\n",
      "Loss at epoch 53: 0.991292099864468\n",
      "Loss at epoch 54: 0.8307376454456531\n",
      "Loss at epoch 55: 0.7579411752190263\n",
      "Loss at epoch 56: 0.7144801242032243\n",
      "Loss at epoch 57: 0.6834499958233107\n",
      "Loss at epoch 58: 0.660605484413167\n",
      "Loss at epoch 59: 0.6431388516197037\n",
      "Loss at epoch 60: 0.6322515654860894\n",
      "Loss at epoch 61: 0.6275817134389517\n",
      "Loss at epoch 62: 0.6417375487270915\n",
      "Loss at epoch 63: 0.6667702457992898\n",
      "Loss at epoch 64: 0.7497959773286749\n",
      "Loss at epoch 65: 0.7913551786503965\n",
      "Loss at epoch 66: 0.8296930478445718\n",
      "Loss at epoch 67: 0.7343397635528947\n",
      "Loss at epoch 68: 0.6660871482791484\n",
      "Loss at epoch 69: 0.5997303507483457\n",
      "Loss at epoch 70: 0.5747531823202252\n",
      "Loss at epoch 71: 0.5524939812428773\n",
      "Loss at epoch 72: 0.5414506862449445\n",
      "Loss at epoch 73: 0.5289675066173583\n",
      "Loss at epoch 74: 0.5220531959644492\n",
      "Loss at epoch 75: 0.5134993050388479\n",
      "Loss at epoch 76: 0.509035331085209\n",
      "Loss at epoch 77: 0.502665608641093\n",
      "Loss at epoch 78: 0.500364645583253\n",
      "Loss at epoch 79: 0.49548210414530847\n",
      "Loss at epoch 80: 0.4957744985819779\n",
      "Loss at epoch 81: 0.49194075254193487\n",
      "Loss at epoch 82: 0.49590014636665347\n",
      "Loss at epoch 83: 0.4926045669381734\n",
      "Loss at epoch 84: 0.5016372947275538\n",
      "Loss at epoch 85: 0.498227742488286\n",
      "Loss at epoch 86: 0.512680861123153\n",
      "Loss at epoch 87: 0.5093046627462294\n",
      "Loss at epoch 88: 0.5260152598290484\n",
      "Loss at epoch 89: 0.5252004428651191\n",
      "Loss at epoch 90: 0.5372384512202075\n",
      "Loss at epoch 91: 0.537549113641703\n",
      "Loss at epoch 92: 0.5328000377169456\n",
      "Loss at epoch 93: 0.5218622169016598\n",
      "Loss at epoch 94: 0.5010028912042621\n",
      "Loss at epoch 95: 0.4825394415501205\n",
      "Loss at epoch 96: 0.46641502864992757\n",
      "Loss at epoch 97: 0.45422594673375044\n",
      "Loss at epoch 98: 0.44632106166499314\n",
      "Loss at epoch 99: 0.4406318173795204\n",
      "Loss at epoch 100: 0.43586619045031894\n",
      "Loss at epoch 101: 0.43404434286372223\n",
      "Loss at epoch 102: 0.42958794998494854\n",
      "Loss at epoch 103: 0.4301415462168946\n",
      "Loss at epoch 104: 0.42495353944989217\n",
      "Loss at epoch 105: 0.42704369824437843\n",
      "Loss at epoch 106: 0.42088779630396933\n",
      "Loss at epoch 107: 0.4239348462056795\n",
      "Loss at epoch 108: 0.4168282096487999\n",
      "Loss at epoch 109: 0.42020128131491646\n",
      "Loss at epoch 110: 0.41238775619293827\n",
      "Loss at epoch 111: 0.4154483389254514\n",
      "Loss at epoch 112: 0.4073618867229702\n",
      "Loss at epoch 113: 0.40969003535267573\n",
      "Loss at epoch 114: 0.4018538241051384\n",
      "Loss at epoch 115: 0.40325374082201576\n",
      "Loss at epoch 116: 0.3960666985479285\n",
      "Loss at epoch 117: 0.39659147200585715\n",
      "Loss at epoch 118: 0.39025540042902623\n",
      "Loss at epoch 119: 0.3900783573797805\n",
      "Loss at epoch 120: 0.38467579817527914\n",
      "Loss at epoch 121: 0.3840590243045687\n",
      "Loss at epoch 122: 0.37954759155471723\n",
      "Loss at epoch 123: 0.37870243557346167\n",
      "Loss at epoch 124: 0.37495735458403895\n",
      "Loss at epoch 125: 0.3740149501477244\n",
      "Loss at epoch 126: 0.370870589611076\n",
      "Loss at epoch 127: 0.3698898474291083\n",
      "Loss at epoch 128: 0.36719897396359225\n",
      "Loss at epoch 129: 0.36622343555079817\n",
      "Loss at epoch 130: 0.36388659797565587\n",
      "Loss at epoch 131: 0.3629386245353399\n",
      "Loss at epoch 132: 0.36086875269770174\n",
      "Loss at epoch 133: 0.3599550540378556\n",
      "Loss at epoch 134: 0.3580802461602947\n",
      "Loss at epoch 135: 0.35720033023962994\n",
      "Loss at epoch 136: 0.35547688657927956\n",
      "Loss at epoch 137: 0.3546253869964658\n",
      "Loss at epoch 138: 0.3530185919278425\n",
      "Loss at epoch 139: 0.3522045382052037\n",
      "Loss at epoch 140: 0.3506982307979935\n",
      "Loss at epoch 141: 0.3499220898440674\n",
      "Loss at epoch 142: 0.34850017190310945\n",
      "Loss at epoch 143: 0.3477385477510733\n",
      "Loss at epoch 144: 0.3463758646130821\n",
      "Loss at epoch 145: 0.34564629660239415\n",
      "Loss at epoch 146: 0.34433906213512516\n",
      "Loss at epoch 147: 0.3436366198572119\n",
      "Loss at epoch 148: 0.34238173488805584\n",
      "Loss at epoch 149: 0.3417041804104159\n",
      "Loss at epoch 150: 0.34048778385928485\n",
      "Loss at epoch 151: 0.33983210470062203\n",
      "Loss at epoch 152: 0.3386507056410041\n",
      "Loss at epoch 153: 0.33801572404803865\n",
      "Loss at epoch 154: 0.33686907276493805\n",
      "Loss at epoch 155: 0.336257456733761\n",
      "Loss at epoch 156: 0.3351371127551776\n",
      "Loss at epoch 157: 0.33454513817642423\n",
      "Loss at epoch 158: 0.3334417120988616\n",
      "Loss at epoch 159: 0.3328552479249918\n",
      "Loss at epoch 160: 0.3317759291942285\n",
      "Loss at epoch 161: 0.3311999547117117\n",
      "Loss at epoch 162: 0.33012578726497116\n",
      "Loss at epoch 163: 0.3295565520103124\n",
      "Loss at epoch 164: 0.3284943797819885\n",
      "Loss at epoch 165: 0.3279221512120407\n",
      "Loss at epoch 166: 0.32687797494649135\n",
      "Loss at epoch 167: 0.3263063335740808\n",
      "Loss at epoch 168: 0.3252774262421578\n",
      "Loss at epoch 169: 0.32470177654021254\n",
      "Loss at epoch 170: 0.3236884561235852\n",
      "Loss at epoch 171: 0.323108738909055\n",
      "Loss at epoch 172: 0.3221183131240899\n",
      "Loss at epoch 173: 0.3215279063380648\n",
      "Loss at epoch 174: 0.3205533511456252\n",
      "Loss at epoch 175: 0.3199574396150858\n",
      "Loss at epoch 176: 0.3190069928706875\n",
      "Loss at epoch 177: 0.31840375261120885\n",
      "Loss at epoch 178: 0.3174793145679538\n",
      "Loss at epoch 179: 0.31686987038455533\n",
      "Loss at epoch 180: 0.3159631896438188\n",
      "Loss at epoch 181: 0.3153531628703513\n",
      "Loss at epoch 182: 0.3144682798154034\n",
      "Loss at epoch 183: 0.3138418804265256\n",
      "Loss at epoch 184: 0.3129870877789533\n",
      "Loss at epoch 185: 0.31235379736302465\n",
      "Loss at epoch 186: 0.31153114499601214\n",
      "Loss at epoch 187: 0.31089876474589095\n",
      "Loss at epoch 188: 0.31009644582323886\n",
      "Loss at epoch 189: 0.3094709050235707\n",
      "Loss at epoch 190: 0.3086978011222765\n",
      "Loss at epoch 191: 0.3080810028119896\n",
      "Loss at epoch 192: 0.3073325974463609\n",
      "Loss at epoch 193: 0.30672093488776064\n",
      "Loss at epoch 194: 0.3059977869903353\n",
      "Loss at epoch 195: 0.30539054124294407\n",
      "Loss at epoch 196: 0.3046864634724737\n",
      "Loss at epoch 197: 0.30408370378609934\n",
      "Loss at epoch 198: 0.30339917042710746\n",
      "Loss at epoch 199: 0.3028046663621791\n",
      "Loss at epoch 200: 0.3021380314628911\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    out, cache = forward_prop(train_set_x, W1, b1, W2, b2)\n",
    "\n",
    "    loss = cross_entropy_loss(out, y)\n",
    "\n",
    "    W2, b2, W1, b1 = back_prop(cache, y, W2, b2, W1, b1)\n",
    "\n",
    "    print(\"Loss at epoch {}: {}\".format(epoch + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:29:13.541117Z",
     "start_time": "2021-05-07T12:29:13.412434Z"
    }
   },
   "outputs": [],
   "source": [
    "pred, _ = forward_prop(test_set_x,  W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:29:15.498839Z",
     "start_time": "2021-05-07T12:29:15.484265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.9%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy(pred, test_set_y)\n",
    "print(\"Test accuracy: {}%\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T12:52:22.862145Z",
     "start_time": "2021-05-07T12:52:22.850385Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = np.random.normal(0, 0.001, (hidden_layer_size, train_set_x.shape[1]))\n",
    "b1 = np.zeros(hidden_layer_size)\n",
    "W2 = np.random.normal(0, 0.001, (num_classes, hidden_layer_size))\n",
    "b2 = np.zeros(num_classes)\n",
    "\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T13:01:02.027584Z",
     "start_time": "2021-05-07T12:53:18.932467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1: 2.3021153915245605\n",
      "Train loss at epoch 2: 2.3019672460723855\n",
      "Train loss at epoch 3: 2.3018111841595736\n",
      "Train loss at epoch 4: 2.3016357992124186\n",
      "Train loss at epoch 5: 2.3014239257461457\n",
      "Train loss at epoch 6: 2.301147392315042\n",
      "Train loss at epoch 7: 2.300763563054119\n",
      "Train loss at epoch 8: 2.3002026114008527\n",
      "Train loss at epoch 9: 2.2993521345075045\n",
      "Train loss at epoch 10: 2.298029784568725\n",
      "Train loss at epoch 11: 2.295941617597507\n",
      "Train loss at epoch 12: 2.292617410537498\n",
      "Train loss at epoch 13: 2.2873239660939855\n",
      "Train loss at epoch 14: 2.2789604150882417\n",
      "Train loss at epoch 15: 2.265989103042924\n",
      "Train loss at epoch 16: 2.2465089692469373\n",
      "Train loss at epoch 17: 2.2185874512945563\n",
      "Train loss at epoch 18: 2.180677763980134\n",
      "Train loss at epoch 19: 2.131811852144464\n",
      "Train loss at epoch 20: 2.070958090082755\n",
      "Train loss at epoch 21: 1.997128936836197\n",
      "Train loss at epoch 22: 1.9105586842265136\n",
      "Train loss at epoch 23: 1.8138270379603862\n",
      "Train loss at epoch 24: 1.7115646227082923\n",
      "Train loss at epoch 25: 1.6087981548894421\n",
      "Train loss at epoch 26: 1.509640027203735\n",
      "Train loss at epoch 27: 1.4169188565053996\n",
      "Train loss at epoch 28: 1.3323632042037536\n",
      "Train loss at epoch 29: 1.2567542517787098\n",
      "Train loss at epoch 30: 1.1900037836787556\n",
      "Train loss at epoch 31: 1.131265573340456\n",
      "Train loss at epoch 32: 1.0794565141028913\n",
      "Train loss at epoch 33: 1.0334268067740726\n",
      "Train loss at epoch 34: 0.9921981952219033\n",
      "Train loss at epoch 35: 0.9549283461959546\n",
      "Train loss at epoch 36: 0.9209887620861751\n",
      "Train loss at epoch 37: 0.8897459438924628\n",
      "Train loss at epoch 38: 0.8608457071380184\n",
      "Train loss at epoch 39: 0.8340234468924351\n",
      "Train loss at epoch 40: 0.8090094509277036\n",
      "Train loss at epoch 41: 0.7856857399367444\n",
      "Train loss at epoch 42: 0.7637480499005476\n",
      "Train loss at epoch 43: 0.7432794166543456\n",
      "Train loss at epoch 44: 0.724035246982023\n",
      "Train loss at epoch 45: 0.7060492103803585\n",
      "Train loss at epoch 46: 0.6892011274856089\n",
      "Train loss at epoch 47: 0.6734077263285873\n",
      "Train loss at epoch 48: 0.658640080636143\n",
      "Train loss at epoch 49: 0.6447975403738769\n",
      "Train loss at epoch 50: 0.6318078095105039\n",
      "Train loss at epoch 51: 0.6196490887279744\n",
      "Train loss at epoch 52: 0.6081763876494998\n",
      "Train loss at epoch 53: 0.5973774481599918\n",
      "Train loss at epoch 54: 0.5872979449737333\n",
      "Train loss at epoch 55: 0.5777242580653119\n",
      "Train loss at epoch 56: 0.5686706985507355\n",
      "Train loss at epoch 57: 0.560126980497411\n",
      "Train loss at epoch 58: 0.552056464675007\n",
      "Train loss at epoch 59: 0.5443858661097696\n",
      "Train loss at epoch 60: 0.537154767971092\n",
      "Train loss at epoch 61: 0.5302089647952581\n",
      "Train loss at epoch 62: 0.5236391888928824\n",
      "Train loss at epoch 63: 0.5173835821222708\n",
      "Train loss at epoch 64: 0.5113946238812209\n",
      "Train loss at epoch 65: 0.5057354552798238\n",
      "Train loss at epoch 66: 0.5002766436547726\n",
      "Train loss at epoch 67: 0.49506618128923024\n",
      "Train loss at epoch 68: 0.49008833777106325\n",
      "Train loss at epoch 69: 0.4853112003123283\n",
      "Train loss at epoch 70: 0.4807640151253781\n",
      "Train loss at epoch 71: 0.4764466601698693\n",
      "Train loss at epoch 72: 0.472214847222793\n",
      "Train loss at epoch 73: 0.46817606628573\n",
      "Train loss at epoch 74: 0.4643495883570052\n",
      "Train loss at epoch 75: 0.46061401726873485\n",
      "Train loss at epoch 76: 0.4570204430671153\n",
      "Train loss at epoch 77: 0.4536091165653076\n",
      "Train loss at epoch 78: 0.4502740074967081\n",
      "Train loss at epoch 79: 0.4470770340616633\n",
      "Train loss at epoch 80: 0.4440186495779612\n",
      "Train loss at epoch 81: 0.4410505610492608\n",
      "Train loss at epoch 82: 0.4381921789810352\n",
      "Train loss at epoch 83: 0.43539623213131945\n",
      "Train loss at epoch 84: 0.4327161432307644\n",
      "Train loss at epoch 85: 0.4301736675405439\n",
      "Train loss at epoch 86: 0.42764601713556705\n",
      "Train loss at epoch 87: 0.4252060640208767\n",
      "Train loss at epoch 88: 0.4228226016919837\n",
      "Train loss at epoch 89: 0.42052192729266524\n",
      "Train loss at epoch 90: 0.4182963516510429\n",
      "Train loss at epoch 91: 0.4161331020604606\n",
      "Train loss at epoch 92: 0.4140442516692245\n",
      "Train loss at epoch 93: 0.41197973302875673\n",
      "Train loss at epoch 94: 0.4100003905202782\n",
      "Train loss at epoch 95: 0.4080510613434023\n",
      "Train loss at epoch 96: 0.40615249604211295\n",
      "Train loss at epoch 97: 0.40430881562215576\n",
      "Train loss at epoch 98: 0.40253570274630907\n",
      "Train loss at epoch 99: 0.4007584540892079\n",
      "Train loss at epoch 100: 0.39903904159282483\n",
      "Train loss at epoch 101: 0.39736013375706875\n",
      "Train loss at epoch 102: 0.3957170446069835\n",
      "Train loss at epoch 103: 0.39412056262523654\n",
      "Train loss at epoch 104: 0.39256429411095906\n",
      "Train loss at epoch 105: 0.391019245573631\n",
      "Train loss at epoch 106: 0.3895067656722947\n",
      "Train loss at epoch 107: 0.38802456526404233\n",
      "Train loss at epoch 108: 0.38657639698184637\n",
      "Train loss at epoch 109: 0.3851642297387904\n",
      "Train loss at epoch 110: 0.383774956802453\n",
      "Train loss at epoch 111: 0.38240017188438896\n",
      "Train loss at epoch 112: 0.3810960758916493\n",
      "Train loss at epoch 113: 0.37976059509353866\n",
      "Train loss at epoch 114: 0.3784641119074383\n",
      "Train loss at epoch 115: 0.3771871594608651\n",
      "Train loss at epoch 116: 0.37592930679121517\n",
      "Train loss at epoch 117: 0.3747046506736701\n",
      "Train loss at epoch 118: 0.37350917167847136\n",
      "Train loss at epoch 119: 0.3723311834885563\n",
      "Train loss at epoch 120: 0.3711583478250702\n",
      "Train loss at epoch 121: 0.370024093383396\n",
      "Train loss at epoch 122: 0.36890582225971624\n",
      "Train loss at epoch 123: 0.3677976034093382\n",
      "Train loss at epoch 124: 0.3666681370423292\n",
      "Train loss at epoch 125: 0.36558342669543975\n",
      "Train loss at epoch 126: 0.3645226081561751\n",
      "Train loss at epoch 127: 0.3634905574411323\n",
      "Train loss at epoch 128: 0.3624398962506652\n",
      "Train loss at epoch 129: 0.36142526523424956\n",
      "Train loss at epoch 130: 0.36043767555887896\n",
      "Train loss at epoch 131: 0.35943455312377454\n",
      "Train loss at epoch 132: 0.35849417172486925\n",
      "Train loss at epoch 133: 0.3575022388620116\n",
      "Train loss at epoch 134: 0.356539662096675\n",
      "Train loss at epoch 135: 0.35560539064461305\n",
      "Train loss at epoch 136: 0.3546735677706098\n",
      "Train loss at epoch 137: 0.35377604299667936\n",
      "Train loss at epoch 138: 0.35286198951395187\n",
      "Train loss at epoch 139: 0.3519907861839202\n",
      "Train loss at epoch 140: 0.35114366362692556\n",
      "Train loss at epoch 141: 0.35024392612364647\n",
      "Train loss at epoch 142: 0.3493924626044967\n",
      "Train loss at epoch 143: 0.3485325265939682\n",
      "Train loss at epoch 144: 0.34768913080817476\n",
      "Train loss at epoch 145: 0.3468758892593385\n",
      "Train loss at epoch 146: 0.3460449233840014\n",
      "Train loss at epoch 147: 0.3452392068428907\n",
      "Train loss at epoch 148: 0.344436321856781\n",
      "Train loss at epoch 149: 0.34372370807574926\n",
      "Train loss at epoch 150: 0.3428679528321786\n",
      "Train loss at epoch 151: 0.342131111622425\n",
      "Train loss at epoch 152: 0.3413396425452028\n",
      "Train loss at epoch 153: 0.3405805242902911\n",
      "Train loss at epoch 154: 0.33983701648032516\n",
      "Train loss at epoch 155: 0.3390987765316396\n",
      "Train loss at epoch 156: 0.3383791972113839\n",
      "Train loss at epoch 157: 0.33763976059136347\n",
      "Train loss at epoch 158: 0.3369414068600241\n",
      "Train loss at epoch 159: 0.33622319842468595\n",
      "Train loss at epoch 160: 0.3355117561183419\n",
      "Train loss at epoch 161: 0.3348152459196209\n",
      "Train loss at epoch 162: 0.3341338685930415\n",
      "Train loss at epoch 163: 0.33344715734511066\n",
      "Train loss at epoch 164: 0.33281445758813477\n",
      "Train loss at epoch 165: 0.33211043658317085\n",
      "Train loss at epoch 166: 0.33142801033190034\n",
      "Train loss at epoch 167: 0.3307764150441388\n",
      "Train loss at epoch 168: 0.330124501530022\n",
      "Train loss at epoch 169: 0.32949992075955964\n",
      "Train loss at epoch 170: 0.3288378165480927\n",
      "Train loss at epoch 171: 0.32820220557212126\n",
      "Train loss at epoch 172: 0.3275858159519346\n",
      "Train loss at epoch 173: 0.32694751026794827\n",
      "Train loss at epoch 174: 0.32632435551642874\n",
      "Train loss at epoch 175: 0.3257192527827316\n",
      "Train loss at epoch 176: 0.3250954884457522\n",
      "Train loss at epoch 177: 0.3245055256873684\n",
      "Train loss at epoch 178: 0.32391131162244063\n",
      "Train loss at epoch 179: 0.3233017094517014\n",
      "Train loss at epoch 180: 0.3227251111655241\n",
      "Train loss at epoch 181: 0.3221110765145615\n",
      "Train loss at epoch 182: 0.3215595490228249\n",
      "Train loss at epoch 183: 0.32094260731889995\n",
      "Train loss at epoch 184: 0.3203817411708414\n",
      "Train loss at epoch 185: 0.3197973000478266\n",
      "Train loss at epoch 186: 0.3192488536835496\n",
      "Train loss at epoch 187: 0.31865185685431724\n",
      "Train loss at epoch 188: 0.31809640471898465\n",
      "Train loss at epoch 189: 0.31752265438554594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 190: 0.3169885140497264\n",
      "Train loss at epoch 191: 0.3164169304766788\n",
      "Train loss at epoch 192: 0.31587568473131133\n",
      "Train loss at epoch 193: 0.3153261528726173\n",
      "Train loss at epoch 194: 0.3147956443613012\n",
      "Train loss at epoch 195: 0.31424430188356245\n",
      "Train loss at epoch 196: 0.3137000233752903\n",
      "Train loss at epoch 197: 0.3131664507228876\n",
      "Train loss at epoch 198: 0.31265277621238563\n",
      "Train loss at epoch 199: 0.31211797437975364\n",
      "Train loss at epoch 200: 0.3115726782220559\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    perm = np.random.permutation(train_set_x.shape[0])\n",
    "    \n",
    "    x_batches = [train_set_x[perm[index : index + batch_size]] \n",
    "                 for index in range(0, train_set_x.shape[0], batch_size)]\n",
    "    y_batches = [y[perm[index : index + batch_size]] for index in range(0, train_set_x.shape[0], batch_size)]\n",
    "\n",
    "    for (batch_x, batch_y) in zip(x_batches, y_batches):\n",
    "        out, cache = forward_prop(batch_x, W1, b1, W2, b2)\n",
    "        W2, b2, W1, b1 = back_prop(cache, batch_y, W2, b2, W1, b1)\n",
    "        \n",
    "    out, _ = forward_prop(train_set_x, W1, b1, W2, b2)\n",
    "    loss = cross_entropy_loss(out, y)\n",
    "\n",
    "    print(\"Train loss at epoch {}: {}\".format(epoch + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T13:01:23.923618Z",
     "start_time": "2021-05-07T13:01:23.772384Z"
    }
   },
   "outputs": [],
   "source": [
    "pred, _ = forward_prop(test_set_x,  W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T13:01:34.312211Z",
     "start_time": "2021-05-07T13:01:34.287709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.36%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy(pred, test_set_y)\n",
    "print(\"Test accuracy: {}%\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
